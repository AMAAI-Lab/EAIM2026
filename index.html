<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <title>Workshop on Emerging AI Technologies for Music</title>
      <!-- CSS -->
      <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans:700,300,400">
      <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
      <link rel="stylesheet" href="assets/font-awesome/css/font-awesome.min.css">
      <link rel="stylesheet" href="assets/elegant-font/code/style.css">
      <link rel="stylesheet" href="assets/css/animate.css">
      <link rel="stylesheet" href="assets/css/magnific-popup.css">
      <link rel="stylesheet" href="assets/css/form-elements.css">
      <link rel="stylesheet" href="assets/css/style.css">
      <link rel="stylesheet" href="assets/css/media-queries.css">
      <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
      <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
      <![endif]-->
      <!-- Favicon -->
      <link rel="shortcut icon" href="assets/ico/favi.png">
   </head>
   <body>
      <!-- Loader -->
      <div class="loader">
         <div class="loader-img"></div>
      </div>
      <!-- Top menu -->
      <nav class="navbar navbar-fixed-top" role="navigation">
         <div class="container">
            <div class="navbar-header">
               <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#top-navbar-1">
               <span class="sr-only">Toggle navigation</span>
               <span class="icon-bar"></span>
               <span class="icon-bar"></span>
               <span class="icon-bar"></span>
               </button>
               <a class="navbar-brand" href="index.html">EAIM Workshop</a>
            </div>
            <div class="collapse navbar-collapse" id="top-navbar-1">
               <ul class="nav navbar-nav navbar-right">
                  <li><a class="scroll-link" href="#top-content">Top</a></li>
                  <li><a class="scroll-link" href="#what-we-do">Description</a></li>
                  <li><a class="scroll-link" href="#cfp">Call for Papers</a></li>
                  <li><a class="scroll-link" href="#portfolio">Speakers</a></li>
                  <li><a class="scroll-link" href="#about">Organizers</a></li>
                  <li><a class="scroll-link" href="#contact">Contact</a></li>
               </ul>
            </div>
         </div>
      </nav>
      <!-- Page title -->
      <div class="page-title top-content">
         <div class="page-title-text wow fadeInUp">
            <h1>International Workshop on Emerging AI Technologies for Music</h1>
            <p><b>Held in conjunction with AAAI-26</b></p>
            <p>26–27 January 2026, Singapore</p>
            <div class="page-title-bottom-link">
               <a class="big-link-1 btn scroll-link" href="#cfp"><b>Call for Papers</b></a>
               <a class="big-link-2 btn scroll-link" href="#portfolio"><b>Speakers</b></a>
            </div>
         </div>
      </div>
      <!-- Workshop Description -->
      <div class="block-3-container section-container what-we-do-container" id="what-we-do">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 block-2-left section-description wow fadeIn">
                  <h2>Workshop Description</h2>
                  <div class="divider-1 wow fadeInUp block-2-box "><span></span></div>
                  <p>
                     This full-day workshop explores the frontier of AI technologies for music, focusing on AI not just as automation but as a collaborator in creative expression. We emphasize keeping humans actively in the loop through prompt-based interfaces, multimodal workflows, interpretable systems, and meaningful user-controls. The workshop highlights controllability, collaboration, and human-centered approaches to music AI, aiming to amplify rather than replace human creativity.
                  </p>
               </div>
            </div>
         </div>
      </div>
      <!-- Call for Papers -->
      <div class="pricing-2-container section-container" id="cfp">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 pricing-2 section-description wow fadeIn">
                  <h2>Call for Papers</h2>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
                  <p>
                     <b>Submission Requirements</b><br/>
                     Maximum 6 pages in LNCS format. Work-in-progress submissions are welcome. Authors are encouraged to include descriptions of prototype implementations. Conceptual designs without evidence of implementation are discouraged. We particularly welcome submissions that emphasize controllability, interpretability, explainability, personalization, human–AI interaction, and collaboration in music systems.
                  </p>
                  <p><b>Topics of Interest include, but are not limited to:</b></p>
                  <ul style="font-size:1.1em; text-align:left; list-style-type:none">
                     <li><span class="icon_plus list-icon"></span>Music composition and generation</li>
                     <li><span class="icon_plus list-icon"></span>Foundational music models</li>
                     <li><span class="icon_plus list-icon"></span>Music production workflows</li>
                     <li><span class="icon_plus list-icon"></span>Music education and pedagogy</li>
                     <li><span class="icon_plus list-icon"></span>Music performance systems</li>
                     <li><span class="icon_plus list-icon"></span>Music information retrieval</li>
                     <li><span class="icon_plus list-icon"></span>Sound design and audio production</li>
                     <li><span class="icon_plus list-icon"></span>Music therapy applications</li>
                     <li><span class="icon_plus list-icon"></span>Music transcription and analysis</li>
                     <li><span class="icon_plus list-icon"></span>Singing voice synthesis</li>
                     <li><span class="icon_plus list-icon"></span>Evaluation of music AI systems</li>
                     <li><span class="icon_plus list-icon"></span>Music recommender systems</li>
                     <li><span class="icon_plus list-icon"></span>Musical instrument design</li>
                     <li><span class="icon_plus list-icon"></span>Robotic musicianship</li>
                     <li><span class="icon_plus list-icon"></span>Optical music recognition</li>
                     <li><span class="icon_plus list-icon"></span>Music theory and musicology</li>
                     <li><span class="icon_plus list-icon"></span>Ethical, cultural and societal implications</li>
                     <li><span class="icon_plus list-icon"></span>Accessibility and inclusion in music AI</li>
                  </ul>
                  <p>
                     <b>Important Dates</b><br/>
                     Paper submission deadline: 29 October 2025<br/>
                     Acceptance/Rejection notice: 14 November 2025<br/>
                     Camera-ready deadline: 30 November 2025<br/>
                     Workshop Date: 26–27 January 2026
                  </p>
                  <p>
                     <b>Publishing Venue</b><br/>
                     Proceedings will be arranged with a publisher (to be announced later).
                  </p>
               </div>
            </div>
         </div>
      </div>
      <!-- Speakers -->
      <div class="clients-container portfolio-container section-container" id="portfolio">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 about section-description wow fadeIn">
                  <h2>Speakers</h2>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
               </div>
            </div>
         </div>
         <!-- Example Speaker -->
         <div class="block-2-container section-container about-block-2-container">
            <div class="container">
               <div class="row">
                  <div class="col-sm-4 block-2-box block-2-left block-2-media wow fadeInLeft">
                     <div class="block-2-img-container">
                        <img src="assets/img/about/ethan.png" alt="Ethan Manilow">
                        <div class="img-container-line line-1"></div>
                        <div class="img-container-line line-2"></div>
                        <div class="img-container-line line-3"></div>
                     </div>
                  </div>
                  <div class="col-sm-8 block-2-box block-2-right wow fadeInUp">
                     <h3>Dr. Ethan Manilow / <span>Google DeepMind</span></h3>
                     <p><b>Bio</b> Ethan is currently a Senior Research Scientist at Google DeepMind on the Magenta Team. He finished his PhD in Computer Science working under Bryan Pardo in the Interactive Audio Lab at Northwestern University. During his PhD, he spent two years as a Student Researcher with Magenta and prior to that, he spent a year and half as Student Researcher at MERL on the Speech and Audio Team. His research centers on making machine learning systems that listen to and understand musical audio in an effort to make tools that can better assist artists. </p>
                  </div>
               </div>
            </div>
         </div>
		 <!-- Speaker: Dr. Elio Quinton -->
		<div class="block-2-container section-container section-container-gray about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-8 block-2-box block-2-left wow fadeInLeft">
					<h3>Dr. Elio Quinton / <span>Universal Music Group</span></h3>
					<p>
					   <b>Bio</b> Elio is VP of Artificial Intelligence at Universal Music Group and founder of the Music & Audio Machine Learning Lab (MAML), the first ML R&D group in the recorded music industry. With a PhD in ML and Audio DSP from Queen Mary University of London, Elio has extensive experience in AI, audio technology, and supporting global artists with next-generation tools.
					</p>
				 </div>
				 <div class="col-sm-4 block-2-box block-2-right wow fadeInLeft">
					<div class="block-2-img-container">
					   <img src="assets/img/about/elio2.png" alt="Elio Quinton">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- Speaker: Prof. Dorien Herremans -->
		<div class="block-2-container section-container about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-4 block-2-box block-2-left block-2-media wow fadeInLeft">
					<div class="block-2-img-container">
					   <img src="assets/img/about/dorien.png" alt="Prof. Dorien Herremans">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
				 <div class="col-sm-8 block-2-box block-2-right wow fadeInUp">
					<h3>Prof. Dorien Herremans / <span>Singapore University of Technology and Design</span></h3>
					<p>
					   <b>Bio</b> Dorien is an Associate Professor at SUTD, where she leads the Audio, Music, and AI (AMAAI) Lab. Previously a Marie Sklodowska-Curie Postdoctoral Fellow at Queen Mary University of London, she was named on the Singapore 100 Women in Tech list in 2021 and was a finalist for the SAIL Award (Super AI Leader) in 2024.
					</p>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- Speaker: Dr. Hanoi Hantrakul -->
		<div class="block-2-container section-container section-container-gray about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-8 block-2-box block-2-left wow fadeInLeft">
					<h3>Dr. Hanoi Hantrakul / <span>ex-Google, ByteDance, TikTok</span></h3>
					<p>
					   <b>Bio</b> Lamtharn "Hanoi" Hantrakul is an AI Research Scientist and AI Sound Artist based in Bangkok, Thailand. He co-invented Google’s open-source DDSP library and the SEED-MUSIC model deployed in Doubao (China’s ChatGPT). As a sound artist ("yaboihanoi"), his music integrates Thai tunings and rhythms. He won the 2022 AI Song Contest and has performed internationally, with his instrument "Fidular" exhibited in the Musical Instruments Museum in Phoenix, AZ.
					</p>
				 </div>
				 <div class="col-sm-4 block-2-box block-2-right wow fadeInLeft">
					<div class="block-2-img-container">
					   <img src="assets/img/about/hanoi.jpeg" alt="Dr. Hanoi Hantrakul">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- Speaker: Dr. Oriol Nieto -->
		<div class="block-2-container section-container about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-4 block-2-box block-2-left block-2-media wow fadeInLeft">
					<div class="block-2-img-container">
					   <img src="assets/img/about/oriol.png" alt="Dr. Oriol Nieto">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
				 <div class="col-sm-8 block-2-box block-2-right wow fadeInUp">
					<h3>Dr. Oriol Nieto / <span>Adobe Research</span></h3>
					<p>
					   <b>Bio</b> Oriol is a Senior Audio Research Engineer in the Sound Design AI Group at Adobe Research. He earned his PhD in Music Data Science from NYU’s Music and Audio Research Lab. His work spans music information retrieval, recommendation systems, and deep learning for audio, and he is also an active musician (guitar, violin, and vocals).
					</p>
				 </div>
			  </div>
		   </div>
		</div>
         <!-- Add more speakers as before -->
      </div>
      <!-- Organizers -->
      <div class="about-container section-container" id="about">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 about section-description wow fadeIn">
                  <h2>Organizers</h2>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
               </div>
            </div>
         </div>
         <!-- Example Organizer -->
         <div class="block-2-container section-container about-block-2-container">
            <div class="container">
               <div class="row">
                  <div class="col-sm-4 block-2-box block-2-left block-2-media wow fadeInLeft">
                     <div class="block-2-img-container">
                        <img src="assets/img/about/keshav.jpg" alt="Keshav Bhandari">
                     </div>
                  </div>
                  <div class="col-sm-8 block-2-box block-2-right wow fadeInUp">
                     <h3>Keshav Bhandari / <span>Queen Mary University of London</span></h3>
                     <p>Keshav is a PhD candidate at the Centre for Digital Music (C4DM), researching neuro-symbolic methods for music composition with a focus on structure and controllability. He is the main contact for EAIM at AAAI-26.</p>
                  </div>
               </div>
            </div>
         </div>
		 <!-- Organizer: Dr. Abhinaba Roy -->
		<div class="block-2-container section-container section-container-gray about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-8 block-2-box block-2-left wow fadeInLeft">
					<h3>Dr. Abhinaba Roy / <span>Singapore University of Technology and Design</span></h3>
					<p>
					   Abhinaba is a Senior Research Fellow at SUTD. He received his PhD in Computer Vision from the Istituto Italiano di Tecnologia in Genoa, Italy. His recent research focuses on AI and music, including text-to-music generation, symbolic music creation, and multimodal music understanding. His work has appeared at ISMIR, IJCNN, AAAI, and other leading venues.
					</p>
				 </div>
				 <div class="col-sm-4 block-2-box block-2-right block-2-media wow fadeInUp">
					<div class="block-2-img-container">
					   <img src="assets/img/about/roy.jpeg" alt="Dr. Abhinaba Roy">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- Organizer: Prof. Simon Colton -->
		<div class="block-2-container section-container about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-4 block-2-box block-2-left block-2-media wow fadeInLeft">
					<div class="block-2-img-container">
					   <img src="assets/img/about/simon.jpeg" alt="Prof. Simon Colton">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
				 <div class="col-sm-8 block-2-box block-2-right wow fadeInUp">
					<h3>Prof. Simon Colton / <span>Queen Mary University of London</span></h3>
					<p>
					   Simon is a Professor of Computational Creativity, AI, and Games at Queen Mary University of London. He has published around 200 papers and led major EPSRC and EU projects. His research explores how to engineer systems capable of taking on creative responsibilities in generative music, arts, and science. He is also active in public engagement and the philosophy of computational creativity.
					</p>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- Organizer: Prof. Dorien Herremans -->
		<div class="block-2-container section-container section-container-gray about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-8 block-2-box block-2-left wow fadeInLeft">
					<h3>Prof. Dorien Herremans / <span>Singapore University of Technology and Design</span></h3>
					<p>
					   Dorien is an Associate Professor at SUTD, where she leads the Audio, Music, and AI (AMAAI) Lab. She was previously a Marie Sklodowska-Curie Postdoctoral Fellow at Queen Mary University of London. Dorien was named to the Singapore 100 Women in Tech list (2021) and was a finalist for the 2024 SAIL Award (Super AI Leader) at the World AI Conference.
					</p>
				 </div>
				 <div class="col-sm-4 block-2-box block-2-right block-2-media wow fadeInUp">
					<div class="block-2-img-container">
					   <img src="assets/img/about/dorien.png" alt="Prof. Dorien Herremans">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
			  </div>
		   </div>
		</div>
         <!-- Add other organizers as before -->
      </div>
      <!-- Contact -->
      <div class="block-2-container section-container contact-container" id="contact">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 block-2 section-description wow fadeIn">
                  <h2>Contact Us</h2>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
                  <p>You can contact the organizers at: k [dot] bhandari [at] qmul.ac.uk</p>
               </div>
            </div>
         </div>
      </div>
      <!-- Footer -->
      <footer>
         <div class="container">
            <div class="row">
               <div class="col-sm-12">
                  <div class="scroll-to-top">
                     <a href="#"><i class="fa fa-chevron-up"></i></a>
                  </div>
               </div>
            </div>
            <div class="row">
               <div class="col-sm-7 footer-copyright">
                  &copy; 2026 Workshop on Emerging AI Technologies for Music (EAIM2026).
               </div>
            </div>
         </div>
      </footer>
      <!-- Javascript -->
      <script src="assets/js/jquery-1.11.1.min.js"></script>
      <script src="assets/bootstrap/js/bootstrap.min.js"></script>
      <script src="assets/js/jquery.backstretch.min.js"></script>
      <script src="assets/js/wow.min.js"></script>
      <script src="assets/js/retina-1.1.0.min.js"></script>
      <script src="assets/js/jquery.magnific-popup.min.js"></script>
      <script src="assets/js/waypoints.min.js"></script>
      <script src="assets/js/jquery.countTo.js"></script>
      <script src="assets/js/masonry.pkgd.min.js"></script>
      <script src="assets/js/scripts.js"></script>
   </body>
</html>
