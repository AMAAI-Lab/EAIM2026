<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <title>1st Workshop on Emerging AI Technologies for Music</title>
      <!-- CSS -->
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:700,300,400">
      <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
      <link rel="stylesheet" href="assets/font-awesome/css/font-awesome.min.css">
      <link rel="stylesheet" href="assets/elegant-font/code/style.css">
      <link rel="stylesheet" href="assets/css/animate.css">
      <link rel="stylesheet" href="assets/css/magnific-popup.css">
      <link rel="stylesheet" href="assets/css/form-elements.css">
      <link rel="stylesheet" href="assets/css/style.css">
      <link rel="stylesheet" href="assets/css/media-queries.css">
      <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
      <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
      <![endif]-->
      <!-- Favicon -->
      <link rel="shortcut icon" href="assets/ico/favi.png">
	   <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-W2W1BTQQ0R"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W2W1BTQQ0R');
</script>
   </head>
   <body>
      <!-- Loader -->
      <div class="loader">
         <div class="loader-img"></div>
      </div>
      <!-- Top menu -->
      <nav class="navbar navbar-fixed-top" role="navigation">
         <div class="container">
            <div class="navbar-header">
               <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#top-navbar-1">
               <span class="sr-only">Toggle navigation</span>
               <span class="icon-bar"></span>
               <span class="icon-bar"></span>
               <span class="icon-bar"></span>
               </button>
               <a class="navbar-brand" href="index.html">EAIM Workshop</a>
            </div>
            <div class="collapse navbar-collapse" id="top-navbar-1">
               <ul class="nav navbar-nav navbar-right">
				   <li><a class="scroll-link" href="#top-content">Top</a></li>
				   <li><a class="scroll-link" href="#what-we-do">Description</a></li>
				   <li><a class="scroll-link" href="#schedule">Schedule</a></li> <li><a class="scroll-link" href="#cfp">Call for Papers</a></li>
				   <li><a class="scroll-link" href="#portfolio">Speakers</a></li>
				   <li><a class="scroll-link" href="#about">Organizers</a></li>
				   <li><a class="scroll-link" href="#contact">Contact</a></li>
				</ul>
            </div>
         </div>
      </nav>
      <!-- Page title -->
      <div class="page-title top-content">
         <div class="page-title-text wow fadeInUp">
            <h1>1st International Workshop on Emerging AI Technologies for Music</h1>
            <p><b>Held in conjunction with AAAI-26</b></p>
            <p>26th January 2026, Singapore</p>
            <div class="page-title-bottom-link">
               <a class="big-link-1 btn scroll-link" href="#cfp"><b>Call for Papers</b></a>
               <a class="big-link-2 btn scroll-link" href="#portfolio"><b>Speakers</b></a>
            </div>
         </div>
      </div>
      <!-- Workshop Description -->
      <div class="block-3-container section-container what-we-do-container" id="what-we-do">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 block-2-left section-description wow fadeIn">
                  <!-- New centered H1 with logo -->
				  <h1 style="text-align:center; margin-bottom:40px;">
				   <img src="assets/img/eaim.jpeg" alt="EAIM Workshop Logo"
					style="max-width:660px; width:100%; height:auto; display:block; margin:0 auto 20px;">
				   1st International Workshop on Emerging AI Technologies for Music
				  </h1>
				  <br></br>
				  <h3>Workshop Description</h3>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
                  <p>
                     This full day workshop, part of a new annual series on the latest developments in AI for music, explores how AI can become a true creative collaborator rather than just another automation tool. As AI transforms music composition, performance, and production, we're seeing an exciting shift from fully autonomous systems toward human-centered approaches. We aim to explore the latest research in human-centric AI for music and discuss how systems can empower humans to shape AI outputs through intuitive interfaces, interactive workflows, interpretable systems and meaningful user-controls. As the field is increasingly shifting toward co-creative and controllable systems, we’ll dive into cutting-edge research and discuss how meaningful musical outcomes can arise through human-machine collaboration. Join us for this inaugural workshop as we explore how to design AI that enhances rather than overshadows human musical creativity.
                  </p>
				  
				  	<div style="margin-top:30px; padding:20px; background:#f9f9f9; border-left:5px solid #2BA560;">
	  <h4 style="margin-top:0;"><strong>Workshop Details</strong></h4>
	  <p style="margin-bottom:10px;">
		<strong>Date:</strong> 26 January 2026 (Monday)<br/>
		<strong>Time:</strong> 8:30 AM – 5:00 PM (Full-day workshop)
	  </p>

	  <p style="margin-bottom:10px;">
		<strong>Venue:</strong><br/>
		Grand Mercure Roxy Hotel<br/>
		50 East Coast Road, Roxy Square<br/>
		Singapore 428769
	  </p>

	  <p style="margin-bottom:10px;">
		The EAIM workshop will be held at a <strong>satellite venue</strong> assigned by AAAI. 
		The venue offers full onsite AV support, a dedicated poster room, scheduled refreshment breaks, 
		and badge pickup facilities for attendees who have not collected their badges at the Singapore EXPO.
	  </p>

	  <p style="margin-bottom:0;">
		<strong>Shuttle Bus Service:</strong><br/>
		Morning shuttles will depart from each official event hotel at <strong>8:00 AM</strong>, arriving in time for the <strong>8:30 AM</strong> workshop start.<br/>
		Evening return buses will depart the venue at <strong>5:30 PM</strong>.
	  </p>
	</div>
				  
               </div>
            </div>
         </div>
      </div>
	  
	  <div class="schedule-container section-container" id="schedule">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 section-description wow fadeIn">
                  <h3>Workshop Schedule</h3>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
                  <p>
                     Join us for a full day of keynotes, oral presentations, and discussions on the future of AI and Music.
                  </p>
               </div>
            </div>
            <div class="row">
               <div class="col-sm-12 wow fadeInUp">
                  <div class="table-responsive">
                     <table class="table table-hover" style="text-align: left; background: #fff; border: 1px solid #ddd;">
                        <thead style="background-color: #f8f8f8; font-weight: bold;">
                           <tr>
                              <th style="width: 15%; padding: 15px;">Time</th>
                              <th style="width: 85%; padding: 15px;">Activity</th>
                           </tr>
                        </thead>
                        <tbody>
                           <tr>
                              <td style="padding: 15px;">09:00</td>
                              <td style="padding: 15px;"><strong>Welcome & Opening Remarks</strong></td>
                           </tr>
                           <tr>
                              <td style="padding: 15px;">09:10</td>
                              <td style="padding: 15px;"><strong>Keynote 1 - Ethan Manilow (Google Deepmind)</strong></td>
                           </tr>
                           <tr>
                              <td style="padding: 15px;">10:00</td>
                              <td style="padding: 15px;"><strong>Keynote 2 - Harry Tan (Universal Music Group)</strong></td>
                           </tr>
                           <tr class="warning" style="background-color: #fcf8e3;">
                              <td style="padding: 15px;">10:50</td>
                              <td style="padding: 15px;"><em>Break</em></td>
                           </tr>
                           
                           <tr>
                              <td style="padding: 15px; vertical-align: top;">11:00</td>
                              <td style="padding: 15px;">
                                 <strong>Oral Presentations</strong> (15 min talk + 5 min Q&A)
                                 <div style="margin-top: 15px;">
                                    
                                    <p style="margin-bottom: 10px;">
                                       <span class="label label-primary">11:00</span> <strong>LLMs can read music, but struggle to hear it: An evaluation of core music perception tasks</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Brandon Carone, Iran Roman, Pablo Ripollés</span>
                                    </p>
                                    
                                    <p style="margin-bottom: 10px;">
                                       <span class="label label-primary">11:20</span> <strong>Conditional Vocal Timbral Technique Conversion via Embedding-Guided Dual Attribute Modulation</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Ting-Chao Hsu, Yi-Hsuan Yang</span>
                                    </p>

                                    <p style="margin-bottom: 10px;">
                                       <span class="label label-primary">11:40</span> <strong>The Circle of Fifths as Latent Geometry in Bach's Well-Tempered Clavier</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Najla Sadek, Joseph Bakarji</span>
                                    </p>

                                    <p style="margin-bottom: 10px;">
                                       <span class="label label-primary">12:00</span> <strong>TS-RaMIA: Membership Inference Attacks for Symbolic Music Generation Models</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Yuxuan Liu, Rui Sang, Peihong Zhang, Zhixin Li, Kunyang Zhang, Shengyuan He, Ye Li, Kaiyi Xu, Shengchen Li</span>
                                    </p>

                                    <p style="margin-bottom: 0;">
                                       <span class="label label-primary">12:20</span> <strong>Prevailing Research Areas for Music AI in the Era of Foundation Models</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Megan Wei, Mateusz Modrzejewski, Aswin Sivaraman, Dorien Herremans</span>
                                    </p>
                                 </div>
                              </td>
                           </tr>

                           <tr class="info" style="background-color: #d9edf7;">
                              <td style="padding: 15px;">13:00</td>
                              <td style="padding: 15px;"><em>Lunch</em></td>
                           </tr>

                           <tr>
                              <td style="padding: 15px;">13:30</td>
                              <td style="padding: 15px;"><strong>Keynote 3 - Dorien Herremans (SUTD)</strong></td>
                           </tr>
                           <tr>
                              <td style="padding: 15px;">14:20</td>
                              <td style="padding: 15px;"><strong>Keynote 4 - Ziqian Ning (ByteDance-Seed & ASLP@NPU)</strong></td>
                           </tr>
                           <tr class="warning" style="background-color: #fcf8e3;">
                              <td style="padding: 15px;">15:10</td>
                              <td style="padding: 15px;"><em>Break</em></td>
                           </tr>
                           <tr>
                              <td style="padding: 15px;">15:30</td>
                              <td style="padding: 15px;"><strong>Panel Discussion</strong></td>
                           </tr>
                           
                           <tr>
                              <td style="padding: 15px; vertical-align: top;">16:00<br/>|<br/>17:00</td>
                              <td style="padding: 15px;">
                                 <strong>Poster Session</strong>
                                 <ul style="list-style-type: none; padding-left: 0; margin-top: 15px;">
                                    
                                    <li style="margin-bottom: 15px;">
                                       <strong>Low-Resource Rhythm Learning of South Asian Beat Structures: Machine Learning Approaches to Nattuvangam</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Ankitha Sudarshan, Atharva Vikas Jadhav, Rohini Srihari</span>
                                    </li>

                                    <li style="margin-bottom: 15px;">
                                       <strong>A Novel Diffusion Model Based Approach for Sleep Therapeutic Music Generation</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Timo Hromadka, Kevin Monteiro, Sam Nallaperuma</span>
                                    </li>

                                    <li style="margin-bottom: 15px;">
                                       <strong>Investigating Timbre Representations in CLAP Across Modalities via Perturbations</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Devyani Hebbar, Brian McFee</span>
                                    </li>

                                    <li style="margin-bottom: 15px;">
                                       <strong>Neural Codec Language Model for Controllable Timbre Transfer in Music Synthesis</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Sheldon Liu, Tianyu Liu, Deepak Dalakoti, Adithya Suresh, Yueying Teng, Xuefeng Liu, Atanu Roy, Randeep Bhatia, Daniel Hatadi, Prabhjeet Ghuman</span>
                                    </li>

                                    <li style="margin-bottom: 15px;">
                                       <strong>Encoder-Only Transformers for Melodic Harmonization: Representation Emergence and Inference Strategies</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Maximos Kaliakatsos-Papakostas, Dimos Makris, Konstantinos Soiledis, Konstantinos Theodoros Tsamis</span>
                                    </li>

                                    <li style="margin-bottom: 15px;">
                                       <strong>SingingSDS: A Singing-Capable Spoken Dialogue System for Conversational Roleplay Applications</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Jionghao Han, Jiatong Shi, Masao Someki, Yuxun Tang, Liulan, Yiwen Zhao, Wenhao Feng, Shinji Watanabe</span>
                                    </li>

                                    <li style="margin-bottom: 15px;">
                                       <strong>Postscript on the Musics of Control</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Yinuo Chen</span>
                                    </li>

                                    <li style="margin-bottom: 15px;">
                                       <strong>Artificial Dancing Intelligence: Neural Cellular Automata for Visual Performance of Music</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Carlos Mariano Salcedo, Eran Egozy</span>
                                    </li>

                                    <li style="margin-bottom: 0px;">
                                       <strong>Silence as Music: Controllable and Interpretable AI for Strategic Silence Placement</strong><br/>
                                       <span style="font-size: 0.9em; color: #666;">Gokul Srinath Seetha Ram</span>
                                    </li>

                                 </ul>
                              </td>
                           </tr>
                        </tbody>
                     </table>
                  </div>
               </div>
            </div>
         </div>
      </div>

      <!-- Call for Papers -->
       <div class="cfp-container section-container">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 cfp section-description wow fadeIn">
                  <h3>Call for Papers</h3>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
                  <p>
                     <b>Submission Requirements</b><br/>
                     We welcome submissions of original research, creative systems, and critical perspectives on emerging AI technologies for music. 
                     Contributions may include theoretical work, empirical studies, system designs, evaluations, or artistic explorations. 
                     While implemented systems and demonstrations are encouraged, strong conceptual and analytical contributions without a prototype are also welcome. 
                     We particularly value submissions that emphasize controllability, interpretability, explainability, personalization, human-AI interaction, and collaboration in music systems.

                     <!-- Conceptual designs without evidence of implementation are discouraged. We particularly welcome submissions that emphasize controllability, interpretability, explainability, personalization, human–AI interaction, and collaboration in music systems. -->
                  </p>
                  <p><b>Topics of Interest include, but are not limited to:</b></p>
                  <ul style="font-size:1.5em; text-align:left; list-style-type:none">
                     <li><span class="icon_plus list-icon"></span>Music composition and generation</li>
                     <li><span class="icon_plus list-icon"></span>Foundational music models</li>
                     <li><span class="icon_plus list-icon"></span>Music production workflows</li>
                     <li><span class="icon_plus list-icon"></span>Music education and pedagogy</li>
                     <li><span class="icon_plus list-icon"></span>Music performance systems</li>
                     <li><span class="icon_plus list-icon"></span>Music information retrieval</li>
                     <li><span class="icon_plus list-icon"></span>Sound design and audio production</li>
                     <li><span class="icon_plus list-icon"></span>Music therapy applications</li>
                     <li><span class="icon_plus list-icon"></span>Music transcription and analysis</li>
                     <li><span class="icon_plus list-icon"></span>Singing voice synthesis</li>
                     <li><span class="icon_plus list-icon"></span>Evaluation of music AI systems</li>
                     <li><span class="icon_plus list-icon"></span>Music recommender systems</li>
                     <li><span class="icon_plus list-icon"></span>Musical instrument design</li>
                     <li><span class="icon_plus list-icon"></span>Robotic musicianship</li>
                     <li><span class="icon_plus list-icon"></span>Optical music recognition</li>
                     <li><span class="icon_plus list-icon"></span>Music theory and musicology</li>
                     <li><span class="icon_plus list-icon"></span>Ethical, cultural and societal implications</li>
                     <li><span class="icon_plus list-icon"></span>Accessibility and inclusion in music AI</li>
                  </ul>
				   <script>
					  const iframe = document.getElementById("countdown_iframe_492508");
					
					  iframe.addEventListener("load", () => {
					    try {
					      // Access the iframe's document
					      const doc = iframe.contentDocument || iframe.contentWindow.document;
					      if (doc && doc.body && doc.body.innerText.includes("Incorrect embedding code")) {
					        iframe.style.display = "none";
					        console.warn("Countdown iframe hidden — incorrect embed detected.");
					      }
					    } catch (e) {
					      // Cross-origin protection: if we can’t access the content, do nothing
					      console.log("Unable to inspect iframe content (cross-origin).");
					    }
					  });
					</script>
                  <p>
                     <b>Important Dates</b><br/>
					  Paper Submission Deadline: <s>24 October 2025</s> <b>Extended to 29 October 2025 (Wednesday)</b><br/>
					  Acceptance/Rejection Notice: 14 November 2025<br/>
					  Camera-Ready Deadline: 14 December 2025<br/>
					  Workshop Date: 26th January 2026 (1 day workshop)
                  </p>
                  <p>
                     <b>Publishing Venue</b><br/>
                     Proceedings will be published as a volume in Proceedings of Machine Learning Research (PMLR).
                  </p>
				  <p>
				   <b>Submission Instructions</b><br/>
				   Paper format: Maximum of 11 pages (excluding references). Please follow the PMLR format using this template: 
				    <a href="https://www.overleaf.com/latex/templates/eaim-template/bvqzcsngcxwz" target="_blank" style="font-weight:bold;  color:#2BA560; ">
					   EAIM Template on Overleaf
					</a>
				   <br/><br/>
				   Submission Portal: 
				   <a href="https://openreview.net/group?id=AAAI.org/2026/Workshop/EAIM" target="_blank" style="font-weight:bold;  color:#2BA560; ;">
					  OpenReview – EAIM Workshop
				   </a>
				   <br/>
				   
					  Note: To sign up for OpenReview, you must use a <span style="color:#F76C3B; font-weight:bold;">university or institution email address</span>. 
					  If you are not affiliated with any institution, account creation with a personal email may take up to 2 weeks so please plan accordingly. 
				   
				  </p>
				  <p>
				   <b>Submission Policies</b><br/>
				   <b>
					Submissions will follow a <span style="color:#F76C3B;">double-blind</span> policy and must be prepared for anonymous review; authors should remove names, affiliations, and any links or references that could reveal their identity.
					</b> <br/><br/>
				   Authors must ensure that all submissions are original and have not been published elsewhere or concurrently submitted to another venue. 
				   Plagiarism in any form, including self-plagiarism, will result in desk rejection. <br/><br/>
				   If generative AI tools are used to produce substantial portions of the writing, analysis, or figures, their use must be clearly disclosed in the paper’s acknowledgments or methodology section. Authors remain fully responsible for the correctness, originality, and integrity of their submissions. <br/><br/>
				   At least one author of each accepted paper must register and present the work at the workshop. 
				</p>
               </div>
             </div>
         </div>
      </div>
      <!-- Speakers -->
      <div class="clients-container portfolio-container section-container" id="portfolio">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 about section-description wow fadeIn">
                  <h3>Speakers</h3>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
               </div>
            </div>
         </div>
         <!-- Example Speaker -->
         <div class="block-2-container section-container about-block-2-container">
            <div class="container">
               <div class="row">
                  <div class="col-sm-4 block-2-box block-2-left block-2-media wow fadeInLeft">
                     <div class="block-2-img-container">
                        <img src="assets/img/about/ethan.png" alt="Ethan Manilow">
                        <div class="img-container-line line-1"></div>
                        <div class="img-container-line line-2"></div>
                        <div class="img-container-line line-3"></div>
                     </div>
                  </div>
                  <div class="col-sm-8 block-2-box block-2-right wow fadeInUp">
                     <h3>Dr. Ethan Manilow / <span>Google DeepMind</span></h3>
                     <p><b>Bio</b> Ethan is currently a Senior Research Scientist at Google DeepMind on the Magenta Team. He finished his PhD in Computer Science working under Bryan Pardo in the Interactive Audio Lab at Northwestern University. During his PhD, he spent two years as a Student Researcher with Magenta and prior to that, he spent a year and half as Student Researcher at MERL on the Speech and Audio Team. His research centers on making machine learning systems that listen to and understand musical audio in an effort to make tools that can better assist artists.  
					 </p>
                  </div>
               </div>
            </div>
         </div>
		 <!-- Speaker: Hao Hao Tan -->
		<div class="block-2-container section-container section-container-gray about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-8 block-2-box block-2-left wow fadeInLeft">
					<h3>Hao Hao Tan / <span>Universal Music Group</span></h3>
					<p>
					   <b>Bio</b> Hao Hao Tan is an AI & Audio Scientist at Universal Music Group, a member of the Music and Audio Machine Learning Lab (MAML), the first ever Machine Learning R&D group in the recorded music industry. MAML’s mission is to invent and build next-generation AI/ML tools to support and empower artists and industry professionals globally.  His work has been published in leading conferences including ISMIR, ICML & WASPAA.
					</p>
				 </div>
				 <div class="col-sm-4 block-2-box block-2-right wow fadeInLeft">
					<div class="block-2-img-container">
					   <img src="assets/img/about/hao_hao_tan.jpeg" alt="Hao Hao Tan">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- Speaker: Prof. Dorien Herremans -->
		<div class="block-2-container section-container about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-4 block-2-box block-2-left block-2-media wow fadeInLeft">
					<div class="block-2-img-container">
					   <img src="assets/img/about/dorien.png" alt="Prof. Dorien Herremans">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
				 <div class="col-sm-8 block-2-box block-2-right wow fadeInUp">
					<h3>Prof. Dorien Herremans / <span>Singapore University of Technology and Design</span></h3>
					<p>
					   <b>Bio</b> Dorien is an Associate Professor at Singapore University of Technology and Design (SUTD), where she leads the Audio, Music, and AI (AMAAI) Lab. Before joining SUTD, she was a Marie Sklodowska-Curie Postdoctoral Fellow at the Centre for Digital Music at Queen Mary University of London. She was also nominated on the Singapore 100 Women in Tech list in 2021, and one of the top 30 SAIL Award (Super AI Leader) Finalists in 2024 at the World AI Conference.
					</p>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- Speaker: Ziqian Ning -->
		<div class="block-2-container section-container about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-8 block-2-box block-2-left wow fadeInLeft">
					<h3>Ziqian Ning / <span>ByteDance-Seed & ASLP@NPU</span></h3>
					<p>
					   <b>Bio</b> Ziqian Ning is an AI Research Scientist at ByteDance-Seed, where he develops large-scale music generation models. His research focuses on generative AI for music and speech, with expertise spanning music generation, voice conversion, and text-to-speech synthesis. Prior to ByteDance, he worked at Microsoft Azure Speech and Netease Fuxi AI Lab, developing real-time voice conversion systems and expressive speech technologies. He holds a Master's degree from Northwestern Polytechnical University under Prof. Lei Xie. His work has been published at leading conferences including AAAI, ICASSP, and INTERSPEECH. Notable contributions include DiffRhythm, the first diffusion-based model for end-to-end full-length song generation, and the DualVC series for low-latency streaming voice conversion. His team achieved first place in the Singing Voice Conversion Challenge 2023, demonstrating human-level naturalness. He continues to explore how AI can transform music creation and empower artists.
					</p>
				 </div>
				 <div class="col-sm-4 block-2-box block-2-right wow fadeInLeft">
					<div class="block-2-img-container">
					   <img src="assets/img/about/Ziqian_Ning.jpg" alt="Ziqian Ning">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- End of Speakers Section -->


      <!-- Organizers -->
      <div class="about-container section-container" id="about">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 about section-description wow fadeIn">
                  <h3>Organizers</h3>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
               </div>
            </div>
         </div>
         <!-- Example Organizer -->
         <div class="block-2-container section-container about-block-2-container">
            <div class="container">
               <div class="row">
                  <div class="col-sm-4 block-2-box block-2-left block-2-media wow fadeInLeft">
                     <div class="block-2-img-container">
                        <img src="assets/img/about/keshav.jpg" alt="Keshav Bhandari">
                     </div>
                  </div>
                  <div class="col-sm-8 block-2-box block-2-right wow fadeInUp">
                     <h3>Keshav Bhandari / <span>Queen Mary University of London</span></h3>
                     <p>Keshav is a PhD candidate at the Centre for Digital Music (C4DM) at Queen Mary University of London supervised by Prof. Simon Colton. His research explores neuro-symbolic methods for music composition with a focus on musical structure and controllability. Prior to Queen Mary, he was part of the Interactive Audio Lab at Northwestern University, Evanston. Over the years, Keshav has published papers across conferences such as NeurIPS, AAAI, IJCNN and recently won the best paper award at EvoMUSART-25 (part of EvoStar). Keshav will be the main contact for the proposed AI music workshop at AAAI-26.</p>
                  </div>
               </div>
            </div>
         </div>
		 <!-- Organizer: Dr. Abhinaba Roy -->
		<div class="block-2-container section-container section-container-gray about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-8 block-2-box block-2-left wow fadeInLeft">
					<h3>Dr. Abhinaba Roy / <span>Singapore University of Technology and Design</span></h3>
					<p>
					   Abhinaba is a senior research fellow at Singapore University of Technology and Design. He received his Ph.D. in Computer Vision in 2019 from the Istituto Italiano di Tecnologia, Genoa, Italy. He has held positions in both industry and academia, focusing on developing and deploying practical AI solutions. In recent years, his research has increasingly focused on the intersection of AI and music, particularly in areas such as text-to-music generation, symbolic music creation, and multimodal music understanding. His work has been published in leading conferences including ISMIR, IJCNN, AAAI, and others.
					</p>
				 </div>
				 <div class="col-sm-4 block-2-box block-2-right block-2-media wow fadeInUp">
					<div class="block-2-img-container">
					   <img src="assets/img/about/roy.jpeg" alt="Dr. Abhinaba Roy">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- Organizer: Prof. Simon Colton -->
		<div class="block-2-container section-container about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-4 block-2-box block-2-left block-2-media wow fadeInLeft">
					<div class="block-2-img-container">
					   <img src="assets/img/about/simon.jpeg" alt="Prof. Simon Colton">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
				 <div class="col-sm-8 block-2-box block-2-right wow fadeInUp">
					<h3>Prof. Simon Colton / <span>Queen Mary University of London</span></h3>
					<p>
					   Simon is a Professor of Computational Creativity, AI and Games in EECS at Queen Mary University of London. He was previously an EPSRC leadership fellow at Imperial College and Goldsmiths College, and held an ERA Chair at Falmouth University. He is an AI researcher with around 200 publications whose work has won national and international awards, and has led numerous EPSRC and EU-funded projects. He focuses specifically on questions of Computational Creativity, where researchers study how to engineer systems to take on creative responsibilities in generative music, arts and science projects. Prof. Colton has has written about the philosophy of Computational Creativity and led numerous public engagement projects.
					</p>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- Organizer: Prof. Dorien Herremans -->
		<div class="block-2-container section-container section-container-gray about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-8 block-2-box block-2-left wow fadeInLeft">
					<h3>Prof. Dorien Herremans / <span>Singapore University of Technology and Design</span></h3>
					<p>
					   Dorien is an Associate Professor at Singapore University of Technology and Design (SUTD), where she leads the Audio, Music, and AI (AMAAI) Lab. Before joining SUTD, she was a Marie Sklodowska-Curie Postdoctoral Fellow at the Centre for Digital Music at Queen Mary University of London. She was also nominated on the Singapore 100 Women in Tech list in 2021, and one of the top 30 SAIL Award (Super AI Leader) Finalists in 2024 at the World AI Conference.
					</p>
				 </div>
				 <div class="col-sm-4 block-2-box block-2-right block-2-media wow fadeInUp">
					<div class="block-2-img-container">
					   <img src="assets/img/about/dorienh.jpg" alt="Prof. Dorien Herremans">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
			  </div>
		   </div>
		</div>
         <!-- Add other organizers as before -->
      </div>
	  <!-- Programme Committee -->
		<div class="about-container section-container" id="committee">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-12 about section-description wow fadeIn">
					<h3>Programme Committee</h3>
					<div class="divider-1 wow fadeInUp"><span></span></div>
					<p style="text-align:left; font-size:1.5em; line-height:1.6;">
					   Prof. Dorien Herremans, Singapore University of Technology and Design <br/>
					   Keshav Bhandari, PhD candidate, Queen Mary University of London <br/>
					   Dr. Abhinaba Roy, Singapore University of Technology and Design <br/>
					   Prof. Simon Colton, Queen Mary University of London <br/>
					   Prof. Mathieu Barthet, Queen Mary University of London <br/>
					   Dr. Jaeyong Kang, Singapore University of Technology and Design <br/>
					   Dr. Jan Melechovsky, Singapore University of Technology and Design <br/>
					   Dr. Berker Banar, Ellison Institute of Technology Oxford <br/>
					   Benjamin Hayes, Sony CSL, Paris <br/>
					   Shuoyang Zheng, PhD candidate, Queen Mary University of London <br/>
					   Zixun Guo, PhD candidate, Queen Mary University of London <br/>
					   Jordie Shier, PhD candidate, Queen Mary University of London <br/>
					   Marco Pasini, PhD Candidate, Queen Mary University of London <br/>
					   Sungkyun Chang, Research Assistant, Queen Mary University of London <br/>
					   Tongyu Lu, PhD Candidate, Singapore University of Technology and Design <br/>
					   Soumya Sai Vanka, PhD Candidate, Queen Mary University of London <br/>
					   Renhang Liu, Research Assistant, Singapore University of Technology and Design <br/>
					   Dimos Makris, Singapore University of Technology and Design <br/>
					   Maojia Song, Singapore University of Technology and Design <br/>
					   Weisheng Jin, Singapore University of Technology and Design <br/>
					   Anuradha Chopra, PhD Candidate, Singapore University of Technology and Design <br/>
					   Aditya Bhattacharjee, PhD Candidate, Queen Mary University of London <br/>
					   Jinwei Zhao, National University of Singapore <br/>
					   Viet Toan Dinh, PhD Candidate, Université de Lille <br/>
					   Alexandre D'Hooge, Université de Lille <br/>
					   Louis Bradshaw, PhD Candidate, Queen Mary University of London <br/>
					   Francesca Ronchini, PhD Candidate, Polytechnic University of Milan <br/>
					   <br/><br/>
					</p>
				 </div>
			  </div>
		   </div>
		</div>
      <!-- Contact -->
      <div class="block-2-container section-container contact-container" id="contact">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 block-2 section-description wow fadeIn">
                  <h3>Contact Us</h3>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
                  <p>You can contact the organizers at: k [dot] bhandari [at] qmul.ac.uk</p>
               </div>
            </div>
         </div>
      </div>
      <!-- Footer -->
      <footer>
         <div class="container">
            <div class="row">
               <div class="col-sm-12">
                  <div class="scroll-to-top">
                     <a href="#"><i class="fa fa-chevron-up"></i></a>
                  </div>
               </div>
            </div>
            <div class="row">
               <div class="col-sm-7 footer-copyright">
                  &copy; 2026 Workshop on Emerging AI Technologies for Music (EAIM2026).
               </div>
            </div>
         </div>
      </footer>
      <!-- Javascript -->
      <script src="assets/js/jquery-1.11.1.min.js"></script>
      <script src="assets/bootstrap/js/bootstrap.min.js"></script>
      <script src="assets/js/jquery.backstretch.min.js"></script>
      <script src="assets/js/wow.min.js"></script>
      <script src="assets/js/retina-1.1.0.min.js"></script>
      <script src="assets/js/jquery.magnific-popup.min.js"></script>
      <script src="assets/js/waypoints.min.js"></script>
      <script src="assets/js/jquery.countTo.js"></script>
      <script src="assets/js/masonry.pkgd.min.js"></script>
      <script src="assets/js/scripts.js"></script>
   </body>
</html>
