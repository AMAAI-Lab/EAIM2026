<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <title>1st Workshop on Emerging AI Technologies for Music</title>
      <!-- CSS -->
      <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans:700,300,400">
      <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
      <link rel="stylesheet" href="assets/font-awesome/css/font-awesome.min.css">
      <link rel="stylesheet" href="assets/elegant-font/code/style.css">
      <link rel="stylesheet" href="assets/css/animate.css">
      <link rel="stylesheet" href="assets/css/magnific-popup.css">
      <link rel="stylesheet" href="assets/css/form-elements.css">
      <link rel="stylesheet" href="assets/css/style.css">
      <link rel="stylesheet" href="assets/css/media-queries.css">
      <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
      <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
      <![endif]-->
      <!-- Favicon -->
      <link rel="shortcut icon" href="assets/ico/favi.png">
   </head>
   <body>
      <!-- Loader -->
      <div class="loader">
         <div class="loader-img"></div>
      </div>
      <!-- Top menu -->
      <nav class="navbar navbar-fixed-top" role="navigation">
         <div class="container">
            <div class="navbar-header">
               <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#top-navbar-1">
               <span class="sr-only">Toggle navigation</span>
               <span class="icon-bar"></span>
               <span class="icon-bar"></span>
               <span class="icon-bar"></span>
               </button>
               <a class="navbar-brand" href="index.html">EAIM Workshop</a>
            </div>
            <div class="collapse navbar-collapse" id="top-navbar-1">
               <ul class="nav navbar-nav navbar-right">
                  <li><a class="scroll-link" href="#top-content">Top</a></li>
                  <li><a class="scroll-link" href="#what-we-do">Description</a></li>
                  <li><a class="scroll-link" href="#cfp">Call for Papers</a></li>
                  <li><a class="scroll-link" href="#portfolio">Speakers</a></li>
                  <li><a class="scroll-link" href="#about">Organizers</a></li>
                  <li><a class="scroll-link" href="#contact">Contact</a></li>
               </ul>
            </div>
         </div>
      </nav>
      <!-- Page title -->
      <div class="page-title top-content">
         <div class="page-title-text wow fadeInUp">
            <h1>1st International Workshop on Emerging AI Technologies for Music</h1>
            <p><b>Held in conjunction with AAAI-26</b></p>
            <p>26–27 January 2026, Singapore</p>
            <div class="page-title-bottom-link">
               <a class="big-link-1 btn scroll-link" href="#cfp"><b>Call for Papers</b></a>
               <a class="big-link-2 btn scroll-link" href="#portfolio"><b>Speakers</b></a>
            </div>
         </div>
      </div>
      <!-- Workshop Description -->
      <div class="block-3-container section-container what-we-do-container" id="what-we-do">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 block-2-left section-description wow fadeIn">
                  <!-- New centered H1 with logo -->
				  <h1 style="text-align:center; margin-bottom:20px;">
				   <img src="assets/img/eaim.jpeg" alt="EAIM Workshop Logo" 
						style="max-width:220px; width:100%; height:auto; display:block; margin:0 auto 15px;">
				   1st International Workshop on Emerging AI Technologies for Music
				  </h1>
				  <h2>Workshop Description</h2>
                  <div class="divider-1 wow fadeInUp block-2-box "><span></span></div>
                  <p>
                     This full day workshop, part of a new annual series on the latest developments in AI for music will explore the emerging frontier of AI technologies that serve not just as automation tools but as collaborators in creative expression. As AI systems reshape how music is composed, performed, and produced, this workshop will highlight the importance of keeping humans actively in the loop through prompt-based interfaces, multimodal workflows and other interactive AI tools. We aim to explore the latest research in human-centric AI for music and discuss how systems can empower humans to guide, steer, and shape AI outputs through intuitive interfaces, interactive workflows, interpretable systems and meaningful user-controls. While early music AI focused on fully autonomous models, the field is increasingly shifting toward co-creative and controllable systems, reflecting growing recognition that meaningful musical outcomes arise through human-machine collaboration. As the inaugural workshop in this planned annual series, we will explore how AI systems can be designed to amplify rather than replace human creativity.
                  </p>
               </div>
            </div>
         </div>
      </div>
      <!-- Call for Papers -->
      <div class="pricing-2-container section-container" id="cfp">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 pricing-2 section-description wow fadeIn">
                  <h2>Call for Papers</h2>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
                  <p>
                     <b>Submission Requirements</b><br/>
                     Work-in-progress submissions are welcome. Authors are encouraged to include descriptions of prototype implementations. Conceptual designs without evidence of implementation are discouraged. We particularly welcome submissions that emphasize controllability, interpretability, explainability, personalization, human–AI interaction, and collaboration in music systems.
                  </p>
                  <p><b>Topics of Interest include, but are not limited to:</b></p>
                  <ul style="font-size:1.5em; text-align:left; list-style-type:none">
                     <li><span class="icon_plus list-icon"></span>Music composition and generation</li>
                     <li><span class="icon_plus list-icon"></span>Foundational music models</li>
                     <li><span class="icon_plus list-icon"></span>Music production workflows</li>
                     <li><span class="icon_plus list-icon"></span>Music education and pedagogy</li>
                     <li><span class="icon_plus list-icon"></span>Music performance systems</li>
                     <li><span class="icon_plus list-icon"></span>Music information retrieval</li>
                     <li><span class="icon_plus list-icon"></span>Sound design and audio production</li>
                     <li><span class="icon_plus list-icon"></span>Music therapy applications</li>
                     <li><span class="icon_plus list-icon"></span>Music transcription and analysis</li>
                     <li><span class="icon_plus list-icon"></span>Singing voice synthesis</li>
                     <li><span class="icon_plus list-icon"></span>Evaluation of music AI systems</li>
                     <li><span class="icon_plus list-icon"></span>Music recommender systems</li>
                     <li><span class="icon_plus list-icon"></span>Musical instrument design</li>
                     <li><span class="icon_plus list-icon"></span>Robotic musicianship</li>
                     <li><span class="icon_plus list-icon"></span>Optical music recognition</li>
                     <li><span class="icon_plus list-icon"></span>Music theory and musicology</li>
                     <li><span class="icon_plus list-icon"></span>Ethical, cultural and societal implications</li>
                     <li><span class="icon_plus list-icon"></span>Accessibility and inclusion in music AI</li>
                  </ul>
				  <p>
					 Maximum pages and paper format: TBD
				  </p>
                  <p>
                     <b>Important Dates</b><br/>
                     Paper submission deadline: 29 October 2025<br/>
                     Acceptance/Rejection notice: 14 November 2025<br/>
                     Camera-ready deadline: 30 November 2025<br/>
                     Workshop Date: 26–27 January 2026
                  </p>
                  <p>
                     <b>Publishing Venue</b><br/>
                     Proceedings will be arranged with a publisher (to be announced later).
                  </p>
               </div>
            </div>
         </div>
      </div>
      <!-- Speakers -->
      <div class="clients-container portfolio-container section-container" id="portfolio">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 about section-description wow fadeIn">
                  <h2>Speakers</h2>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
               </div>
            </div>
         </div>
         <!-- Example Speaker -->
         <div class="block-2-container section-container about-block-2-container">
            <div class="container">
               <div class="row">
                  <div class="col-sm-4 block-2-box block-2-left block-2-media wow fadeInLeft">
                     <div class="block-2-img-container">
                        <img src="assets/img/about/ethan.png" alt="Ethan Manilow">
                        <div class="img-container-line line-1"></div>
                        <div class="img-container-line line-2"></div>
                        <div class="img-container-line line-3"></div>
                     </div>
                  </div>
                  <div class="col-sm-8 block-2-box block-2-right wow fadeInUp">
                     <h3>Dr. Ethan Manilow / <span>Google DeepMind</span></h3>
                     <p><b>Bio</b> Ethan is currently a Senior Research Scientist at Google DeepMind on the Magenta Team. He finished his PhD in Computer Science working under Bryan Pardo in the Interactive Audio Lab at Northwestern University. During his PhD, he spent two years as a Student Researcher with Magenta and prior to that, he spent a year and half as Student Researcher at MERL on the Speech and Audio Team. His research centers on making machine learning systems that listen to and understand musical audio in an effort to make tools that can better assist artists.  
					 </p>
                  </div>
               </div>
            </div>
         </div>
		 <!-- Speaker: Dr. Elio Quinton -->
		<div class="block-2-container section-container section-container-gray about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-8 block-2-box block-2-left wow fadeInLeft">
					<h3>Dr. Elio Quinton / <span>Universal Music Group</span></h3>
					<p>
					   <b>Bio</b> Elio is a scientist, engineer and leader with over a decade of experience in Artificial Intelligence, Machine Learning, and Audio Technology. Currently VP of Artificial Intelligence at Universal Music Group (UMG) and advisor to creative AI startups, he founded and leads the Music & Audio Machine Learning Lab (MAML), the first ever Machine Learning R\&D group in the recorded music industry. MAML's mission is to invent and build next-generation AI/ML tools to support and empower artists and industry professionals globally. Trained as both a scientist, engineer and musician, Elio holds a PhD in ML and Audio DSP from the Center for Digital Music, a Physics MSc, a Music Technology MA, and a diploma in Commercial Music performance from BIMM London.
					</p>
				 </div>
				 <div class="col-sm-4 block-2-box block-2-right wow fadeInLeft">
					<div class="block-2-img-container">
					   <img src="assets/img/about/elio2.png" alt="Elio Quinton">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- Speaker: Prof. Dorien Herremans -->
		<div class="block-2-container section-container about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-4 block-2-box block-2-left block-2-media wow fadeInLeft">
					<div class="block-2-img-container">
					   <img src="assets/img/about/dorien.png" alt="Prof. Dorien Herremans">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
				 <div class="col-sm-8 block-2-box block-2-right wow fadeInUp">
					<h3>Prof. Dorien Herremans / <span>Singapore University of Technology and Design</span></h3>
					<p>
					   <b>Bio</b> Dorien is an Associate Professor at Singapore University of Technology and Design (SUTD), where she leads the Audio, Music, and AI (AMAAI) Lab. Before joining SUTD, she was a Marie Sklodowska-Curie Postdoctoral Fellow at the Centre for Digital Music at Queen Mary University of London. She was also nominated on the Singapore 100 Women in Tech list in 2021, and one of the top 30 SAIL Award (Super AI Leader) Finalists in 2024 at the World AI Conference.
					</p>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- Speaker: Dr. Hanoi Hantrakul -->
		<div class="block-2-container section-container section-container-gray about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-8 block-2-box block-2-left wow fadeInLeft">
					<h3>Dr. Hanoi Hantrakul / <span>ex-Google, ByteDance, TikTok</span></h3>
					<p>
					   <b>Bio</b> Lamtharn "Hanoi" Hantrakul is an AI Research Scientist and AI Sound Artist based in Bangkok, Thailand. His work explores how machine learning can empower music, arts and culture, particularly from Southeast Asia. With over 8 years of experience in the tech industry, he has developed state-of-the-art Generative AI models at Google, TikTok and ByteDance as a Senior AI Research Scientist. He is co-inventor of notable technologies including Google's open source DDSP library and the music large language model SEED-MUSIC deployed in Doubao (China's ChatGPT).
					   As a sound artist performing under "yaboihanoi," his electronic music incorporates Thai tunings and rhythms. He won the 2022 international AI Song Contest with "Enter Demons and Gods" and has performed at SONAR Music Festival alongside artists like Skrillex and Four Tet. His musical instrument "Fidular" received an A' Silver Award and Core77 Design Award in 2017 and is permanently exhibited at the Musical Instruments Museum in Phoenix, AZ. His work on machine learning and cultural empowerment has been covered by international media including Deutschlandfunk, Scientific American and Fast Company.
					</p>
				 </div>
				 <div class="col-sm-4 block-2-box block-2-right wow fadeInLeft">
					<div class="block-2-img-container">
					   <img src="assets/img/about/hanoi.jpeg" alt="Dr. Hanoi Hantrakul">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
			  </div>
		   </div>
		</div>
         <!-- Add more speakers as before -->
      </div>
      <!-- Organizers -->
      <div class="about-container section-container" id="about">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 about section-description wow fadeIn">
                  <h2>Organizers</h2>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
               </div>
            </div>
         </div>
         <!-- Example Organizer -->
         <div class="block-2-container section-container about-block-2-container">
            <div class="container">
               <div class="row">
                  <div class="col-sm-4 block-2-box block-2-left block-2-media wow fadeInLeft">
                     <div class="block-2-img-container">
                        <img src="assets/img/about/keshav.jpg" alt="Keshav Bhandari">
                     </div>
                  </div>
                  <div class="col-sm-8 block-2-box block-2-right wow fadeInUp">
                     <h3>Keshav Bhandari / <span>Queen Mary University of London</span></h3>
                     <p>Keshav is a PhD candidate at the Centre for Digital Music (C4DM) at Queen Mary University of London supervised by Prof. Simon Colton. His research explores neuro-symbolic methods for music composition with a focus on musical structure and controllability. Prior to Queen Mary, he was part of the Interactive Audio Lab at Northwestern University, Evanston. Over the years, Keshav has published papers across conferences such as NeurIPS, AAAI, IJCNN and recently won the best paper award at EvoMUSART-25 (part of EvoStar). Keshav will be the main contact for the proposed AI music workshop at AAAI-26.</p>
                  </div>
               </div>
            </div>
         </div>
		 <!-- Organizer: Dr. Abhinaba Roy -->
		<div class="block-2-container section-container section-container-gray about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-8 block-2-box block-2-left wow fadeInLeft">
					<h3>Dr. Abhinaba Roy / <span>Singapore University of Technology and Design</span></h3>
					<p>
					   Abhinaba is a senior research fellow at Singapore University of Technology and Design. He received his Ph.D. in Computer Vision in 2019 from the Istituto Italiano di Tecnologia, Genoa, Italy. He has held positions in both industry and academia, focusing on developing and deploying practical AI solutions. In recent years, his research has increasingly focused on the intersection of AI and music, particularly in areas such as text-to-music generation, symbolic music creation, and multimodal music understanding. His work has been published in leading conferences including ISMIR, IJCNN, AAAI, and others.
					</p>
				 </div>
				 <div class="col-sm-4 block-2-box block-2-right block-2-media wow fadeInUp">
					<div class="block-2-img-container">
					   <img src="assets/img/about/roy.jpeg" alt="Dr. Abhinaba Roy">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- Organizer: Prof. Simon Colton -->
		<div class="block-2-container section-container about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-4 block-2-box block-2-left block-2-media wow fadeInLeft">
					<div class="block-2-img-container">
					   <img src="assets/img/about/simon.jpeg" alt="Prof. Simon Colton">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
				 <div class="col-sm-8 block-2-box block-2-right wow fadeInUp">
					<h3>Prof. Simon Colton / <span>Queen Mary University of London</span></h3>
					<p>
					   Simon is a Professor of Computational Creativity, AI and Games in EECS at Queen Mary University of London. He was previously an EPSRC leadership fellow at Imperial College and Goldsmiths College, and held an ERA Chair at Falmouth University. He is an AI researcher with around 200 publications whose work has won national and international awards, and has led numerous EPSRC and EU-funded projects. He focuses specifically on questions of Computational Creativity, where researchers study how to engineer systems to take on creative responsibilities in generative music, arts and science projects. Prof. Colton has has written about the philosophy of Computational Creativity and led numerous public engagement projects.
					</p>
				 </div>
			  </div>
		   </div>
		</div>
		<!-- Organizer: Prof. Dorien Herremans -->
		<div class="block-2-container section-container section-container-gray about-block-2-container">
		   <div class="container">
			  <div class="row">
				 <div class="col-sm-8 block-2-box block-2-left wow fadeInLeft">
					<h3>Prof. Dorien Herremans / <span>Singapore University of Technology and Design</span></h3>
					<p>
					   Dorien is an Associate Professor at Singapore University of Technology and Design (SUTD), where she leads the Audio, Music, and AI (AMAAI) Lab. Before joining SUTD, she was a Marie Sklodowska-Curie Postdoctoral Fellow at the Centre for Digital Music at Queen Mary University of London. She was also nominated on the Singapore 100 Women in Tech list in 2021, and one of the top 30 SAIL Award (Super AI Leader) Finalists in 2024 at the World AI Conference.
					</p>
				 </div>
				 <div class="col-sm-4 block-2-box block-2-right block-2-media wow fadeInUp">
					<div class="block-2-img-container">
					   <img src="assets/img/about/dorien.png" alt="Prof. Dorien Herremans">
					   <div class="img-container-line line-1"></div>
					   <div class="img-container-line line-2"></div>
					   <div class="img-container-line line-3"></div>
					</div>
				 </div>
			  </div>
		   </div>
		</div>
         <!-- Add other organizers as before -->
      </div>
      <!-- Contact -->
      <div class="block-2-container section-container contact-container" id="contact">
         <div class="container">
            <div class="row">
               <div class="col-sm-12 block-2 section-description wow fadeIn">
                  <h2>Contact Us</h2>
                  <div class="divider-1 wow fadeInUp"><span></span></div>
                  <p>You can contact the organizers at: k [dot] bhandari [at] qmul.ac.uk</p>
               </div>
            </div>
         </div>
      </div>
      <!-- Footer -->
      <footer>
         <div class="container">
            <div class="row">
               <div class="col-sm-12">
                  <div class="scroll-to-top">
                     <a href="#"><i class="fa fa-chevron-up"></i></a>
                  </div>
               </div>
            </div>
            <div class="row">
               <div class="col-sm-7 footer-copyright">
                  &copy; 2026 Workshop on Emerging AI Technologies for Music (EAIM2026).
               </div>
            </div>
         </div>
      </footer>
      <!-- Javascript -->
      <script src="assets/js/jquery-1.11.1.min.js"></script>
      <script src="assets/bootstrap/js/bootstrap.min.js"></script>
      <script src="assets/js/jquery.backstretch.min.js"></script>
      <script src="assets/js/wow.min.js"></script>
      <script src="assets/js/retina-1.1.0.min.js"></script>
      <script src="assets/js/jquery.magnific-popup.min.js"></script>
      <script src="assets/js/waypoints.min.js"></script>
      <script src="assets/js/jquery.countTo.js"></script>
      <script src="assets/js/masonry.pkgd.min.js"></script>
      <script src="assets/js/scripts.js"></script>
   </body>
</html>
